{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10 : SageMaker Endpoint Production Variants and Deployment Strategies\n",
    "\n",
    "This notebook demonstrates how to update a deployed model using SageMaker Endpoint Production variants.  Specifically it demonstrates the A/B deployment strategy.  You can use this notebook as a starting point to implement other strategies discussed in Chapter 10, since the APIs used to either deploy a new endpoint or update an existing endpoint remain the same. \n",
    "\n",
    "### Overview\n",
    "\n",
    "1. Set up\n",
    "2. Prepare (Reuse or Train) models to deploy and update\n",
    "3. Create an endpoint (with single production variant)\n",
    "4. Invoke the endpoint\n",
    "5. Update endpoint (with two production variants)\n",
    "6. CloudWatch Analysis\n",
    "7. Update endpoint\n",
    "8. Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Imports\n",
    "import sagemaker\n",
    "import boto3\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.session import production_variant\n",
    "from botocore.response import StreamingBody"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = 'datascience-environment-notebookinstance--06dc7a0224df'\n",
    "s3_prefix = 'prepared'\n",
    "m_prefix = 'xgboost-sample'\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Setup service clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = boto3.Session().client(\"sagemaker\")\n",
    "smrt = boto3.Session().client(\"sagemaker-runtime\")\n",
    "s3 = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define variable to toggle between using trained models from previous chapters and training the models in this notebook\n",
    "\n",
    "### Set use_trained_models to True, if you have XGBoost models trained in previous chapters, use those models to save training time and costs.\n",
    "### To train models in this notebook set use_trained_model to False.\n",
    "#use_trained_models = 'False'\n",
    "use_trained_models = 'True'\n",
    "\n",
    "if use_trained_models == 'True':\n",
    "    print(\"Using models trained before\")\n",
    "else:\n",
    "    print(\"Train the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2 - Prepare (Reuse or Train) models to deploy and update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use the XGBoost models previously trained\n",
    "### Note: Update to use the models available in your datascience account\n",
    "if use_trained_models == 'True':\n",
    "    model_name_1='sagemaker-xgboost-2021-06-24-02-34-20-510'\n",
    "    model_name_2='sagemaker-xgboost-2021-06-24-02-47-08-912'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_trained_models == 'False':\n",
    "\n",
    "    # set an output path where the trained model will be saved\n",
    "    output_path = 's3://{}/{}/{}/output'.format(s3_bucket, m_prefix, 'xgboost')\n",
    "    \n",
    "    # this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "    # specify the repo_version depending on your preference.\n",
    "    xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-1\")\n",
    "    \n",
    "    # define the data type and paths to the training and validation datasets\n",
    "    content_type = \"csv\"\n",
    "    train_input = TrainingInput(\"s3://{}/{}/{}/\".format(s3_bucket, s3_prefix, 'train'), content_type=content_type)\n",
    "    validation_input = TrainingInput(\"s3://{}/{}/{}/\".format(s3_bucket, s3_prefix, 'validation'), content_type=content_type)\n",
    "\n",
    "    #### Train and get the name of the first model \n",
    "    # initialize hyperparameters\n",
    "    hyperparameters_1 = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"reg:squarederror\",\n",
    "        \"num_round\":\"5\"}\n",
    "\n",
    "    # construct a SageMaker estimator that calls the xgboost-container\n",
    "    estimator_1 = sagemaker.estimator.Estimator(image_uri=xgboost_container, \n",
    "                                          hyperparameters=hyperparameters_1,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.12xlarge', \n",
    "                                          volume_size=200, # 5 GB \n",
    "                                          output_path=output_path)\n",
    "\n",
    "\n",
    "    # execute the XGBoost training job\n",
    "    estimator_1.fit({'train': train_input, 'validation': validation_input})\n",
    "    \n",
    "    training_job_name_1 = estimator_1.latest_training_job.name\n",
    "    \n",
    "    model_name_1 = sagemaker_session.create_model_from_job(training_job_name_1)\n",
    "    \n",
    "    \n",
    "    #### Train and get the name of the second model \n",
    "    # initialize hyperparameters\n",
    "    hyperparameters_2 = {\n",
    "        \"max_depth\":\"10\",  ##Different value of the hyperparameter\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"reg:squarederror\",\n",
    "        \"num_round\":\"5\"}\n",
    "\n",
    "    # construct a SageMaker estimator that calls the xgboost-container\n",
    "    estimator_2 = sagemaker.estimator.Estimator(image_uri=xgboost_container, \n",
    "                                          hyperparameters=hyperparameters_2,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.12xlarge', \n",
    "                                          volume_size=200, # 5 GB \n",
    "                                          output_path=output_path)\n",
    "\n",
    "\n",
    "    # execute the XGBoost training job\n",
    "    estimator_2.fit({'train': train_input, 'validation': validation_input})\n",
    "    \n",
    "    training_job_name_2 = estimator_2.latest_training_job.name\n",
    "    \n",
    "    model_name_2 = sagemaker_session.create_model_from_job(training_job_name_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model 1 : \" , model_name_1)\n",
    "print(\"Model 2 : \" , model_name_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Create an endpoint (with single production variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create production variant A\n",
    "variantA = production_variant(model_name=model_name_1,\n",
    "                              instance_type=\"ml.m5.xlarge\",\n",
    "                              initial_instance_count=1,\n",
    "                              variant_name='VariantA',\n",
    "                              initial_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable for endpoint name\n",
    "endpoint_name=f\"abtest-{datetime.now():%Y-%m-%d-%H-%M-%S}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##First create an endpoint with single variant\n",
    "##Note this step automatically creates an endpointconfig with same name as the endpoint, that you can update later\n",
    "\n",
    "#Create an endpoint with a single production variant\n",
    "sagemaker_session.endpoint_from_production_variants(\n",
    "    name=endpoint_name,\n",
    "    production_variants=[variantA]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Invoke the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get the file name at index from the 'prefix' folder\n",
    "def get_file_in_bucket(prefix,index):\n",
    "    response = s3.list_objects(\n",
    "        Bucket=s3_bucket,\n",
    "        Prefix=s3_prefix + \"/\" + prefix\n",
    "    )\n",
    "    ## At '0' index you will find the SUCCESS/FAILURE of file uploades to S3. First data file is at index 1\n",
    "    file_name = response['Contents'][index]['Key']\n",
    "    print(\"Returing file name : \" + file_name)\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Download the test files to execute inferences\n",
    "s3.download_file(s3_bucket, get_file_in_bucket('test',1), 't_file.csv')\n",
    "\n",
    "with open('t_file.csv', 'r') as TF:\n",
    "    t_lines = TF.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define a method to run inferences against the endpoint\n",
    "def get_predictions():\n",
    "    #Skip the first line since it has column headers\n",
    "    for tl in t_lines[1:50]:\n",
    "        #Remove the first column since it is the label\n",
    "        test_list = tl.split(\",\")\n",
    "        test_list.pop(0)\n",
    "        test_string = ','.join([str(elem) for elem in test_list])\n",
    "    \n",
    "        result = smrt.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                   ContentType=\"text/csv\",\n",
    "                                   Body=test_string)\n",
    "        #print(result)                              \n",
    "        rbody = StreamingBody(raw_stream=result['Body'],content_length=int(result['ResponseMetadata']['HTTPHeaders']['content-length']))\n",
    "        print(f\"Result from {result['InvokedProductionVariant']} = {rbody.read().decode('utf-8')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "get_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Update endpoint with two production variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create production variant B\n",
    "variantB = production_variant(model_name=model_name_2,\n",
    "                              instance_type=\"ml.m5.xlarge\",\n",
    "                              initial_instance_count=1,\n",
    "                              variant_name='VariantB',\n",
    "                              initial_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Next update the endpoint to include both production variants\n",
    "endpoint_config_new =f\"abtest-new-config-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "\n",
    "sagemaker_session.create_endpoint_config_from_existing (\n",
    "    existing_config_name=endpoint_name,\n",
    "    new_config_name=endpoint_config_new,\n",
    "    new_production_variants=[variantA,variantB]  ## Two production variants\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Update the endpoint\n",
    "sagemaker_session.update_endpoint(endpoint_name=endpoint_name, endpoint_config_name=endpoint_config_new, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show that you can still get inferences while the endpoint is being updated\n",
    "#Get predictions\n",
    "get_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. CloudWatch Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the CloudWatch metrics generated for the two variants to understand the endpoint behavior.  Here we are plotting the number of invocations of each variant.\n",
    "You can use the same pattern to plot other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define utility methods to retrieve and plot cloudwatch metrics\n",
    "import pandas as pd\n",
    "\n",
    "cw = boto3.Session().client(\"cloudwatch\")\n",
    "\n",
    "def get_invocation_metrics_for_endpoint_variant(endpoint_name, variant_name, start_time, end_time):\n",
    "    metrics = cw.get_metric_statistics(\n",
    "        Namespace=\"AWS/SageMaker\",\n",
    "        MetricName=\"Invocations\",\n",
    "        StartTime=start_time,\n",
    "        EndTime=end_time,\n",
    "        Period=60,\n",
    "        Statistics=[\"Sum\"],\n",
    "        Dimensions=[\n",
    "            {\"Name\": \"EndpointName\", \"Value\": endpoint_name},\n",
    "            {\"Name\": \"VariantName\", \"Value\": variant_name},\n",
    "        ],\n",
    "    )\n",
    "    return (\n",
    "        pd.DataFrame(metrics[\"Datapoints\"])\n",
    "        .sort_values(\"Timestamp\")\n",
    "        .set_index(\"Timestamp\")\n",
    "        .drop(\"Unit\", axis=1)\n",
    "        .rename(columns={\"Sum\": variant_name})\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_endpoint_metrics(start_time=None):\n",
    "    start_time = start_time or datetime.now() - timedelta(minutes=60)\n",
    "    end_time = datetime.now()\n",
    "    metrics_variant1 = get_invocation_metrics_for_endpoint_variant(\n",
    "        endpoint_name, variantA[\"VariantName\"], start_time, end_time\n",
    "    )\n",
    "    metrics_variant2 = get_invocation_metrics_for_endpoint_variant(\n",
    "        endpoint_name, variantB[\"VariantName\"], start_time, end_time\n",
    "    )\n",
    "    metrics_variants = metrics_variant1.join(metrics_variant2, how=\"outer\")\n",
    "    metrics_variants.plot()\n",
    "    return metrics_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Send traffic to endpoint for about 2 minutes.  \n",
    "##You should see both the variants serving traffic, after the endpoint is updated.\n",
    "print(f\"Sending test traffic to the endpoint {endpoint_name}. \\nPlease wait...\")\n",
    "#Skip the first line since it has column headers\n",
    "for tl in t_lines[1:200]:\n",
    "    #print(\".\", end=\"\", flush=True)\n",
    "    #Remove the first column since it is the label\n",
    "    test_list = tl.split(\",\")\n",
    "    test_list.pop(0)\n",
    "    test_string = ','.join([str(elem) for elem in test_list])\n",
    "    \n",
    "    result = smrt.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                   ContentType=\"text/csv\",\n",
    "                                   Body=test_string)\n",
    "    #print(result)                              \n",
    "    rbody = StreamingBody(raw_stream=result['Body'],content_length=int(result['ResponseMetadata']['HTTPHeaders']['content-length']))\n",
    "    print(f\"Result from {result['InvokedProductionVariant']} = {rbody.read().decode('utf-8')}\")\n",
    "    time.sleep(0.5)  \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Waiting a minute for initial metric creation...\")\n",
    "time.sleep(60)\n",
    "plot_endpoint_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Update endpoint to contain just the VariantB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 - Gradually update the weights of each production variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the product variant weight to route 60% of traffic to VariantB\n",
    "sm.update_endpoint_weights_and_capacities(\n",
    "    EndpointName=endpoint_name,\n",
    "    DesiredWeightsAndCapacities=[\n",
    "        {\"DesiredWeight\": 4, \"VariantName\": variantA[\"VariantName\"]},\n",
    "        {\"DesiredWeight\": 6, \"VariantName\": variantB[\"VariantName\"]},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.2 - Alternatively, update the endpoint to route all live traffic to VariantB in a single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Update the endpoint to point to VariantB\n",
    "endpoint_config_new =f\"abtest-b-config-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "\n",
    "sagemaker_session.create_endpoint_config_from_existing (\n",
    "    existing_config_name=endpoint_name,\n",
    "    new_config_name=endpoint_config_new,\n",
    "    new_production_variants=[variantB]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Update the endpoint\n",
    "##Note : This step will fail if the endpoint is still updating\n",
    "sagemaker_session.update_endpoint(endpoint_name=endpoint_name, endpoint_config_name=endpoint_config_new, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you do not plan to use this endpoint further, you should delete the endpoint to avoid incurring additional charges.\n",
    "sagemaker_session.delete_endpoint(endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
