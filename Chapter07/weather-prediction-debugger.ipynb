{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug training jobs with Amazon SageMaker Debugger\n",
    "\n",
    "This notebook demonstrates how to use Amazon SageMaker Debugger with a training job.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker Debugger is the capability of Amazon SageMaker that allows debugging machine learning training. The capability helps you monitor the training jobs in near real time.  Using Amazon SageMaker Debugger is a two step process - saving model parameters and analysing the saved information. \n",
    "\n",
    "#### Overview\n",
    "\n",
    "1. Setup\n",
    "2. Train XGBoost model with Amazon SageMaker Debugger enabled\n",
    "3. Manually analyze debugger output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Setup <a id='setup'></a>\n",
    "\n",
    "In this section, we will import the necessary libraries, setup variables and examine dataset used. that was used to train the XGBoost model to predict an individual's income.\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "* The AWS region used to host your model.\n",
    "* The IAM role associated with this SageMaker notebook instance.\n",
    "* The S3 bucket used to store the data used to train the model, save debugger information during training and the trained model artifact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Important**</font>: To use the new Debugger features, you need to upgrade the SageMaker Python SDK and the SMDebug libary. In the following cell, change the third line to `install_needed=True` and run to upgrade the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import IPython\n",
    "install_needed = False  # Set to True to install/upgrade\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install -U sagemaker\n",
    "    !{sys.executable} -m pip install -U smdebug\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.debugger import rule_configs, Rule, DebuggerHookConfig, CollectionConfig\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "from sagemaker.inputs import TrainingInput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Region: us-west-2\n",
      "RoleArn: arn:aws:iam::802439482869:role/DataScienceEnvironment-SageMakerRole-1SVE0FKUVRVO5\n"
     ]
    }
   ],
   "source": [
    "region = boto3.Session().region_name\n",
    "print(\"AWS Region: {}\".format(region))\n",
    "\n",
    "role = get_execution_role()\n",
    "print(\"RoleArn: {}\".format(role))\n",
    "\n",
    "s3_bucket = 'datascience-environment-notebookinstance--06dc7a0224df'\n",
    "s3_prefix  = 'prepared'\n",
    "\n",
    "content_type = \"csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Create the service clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "s3_client = boto3.client('s3', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 S3 bucket and prefix to hold training data, debugger information, and model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get the file name at index from the 'prefix' folder\n",
    "def get_file_in_bucket(prefix,index):\n",
    "    response = s3_client.list_objects(\n",
    "        Bucket=s3_bucket,\n",
    "        Prefix=s3_prefix + \"/\" + prefix\n",
    "    )\n",
    "    ## At '0' index you will find the SUCCESS/FAILURE of file uploades to S3. First data file is at index 1\n",
    "    file_name = response['Contents'][index]['Key']\n",
    "    print(\"Returing file name : \" + file_name)\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returing file name : prepared/train/part-00000-2554f113-947e-46bd-be31-9cd75cb4661c-c000.csv\n",
      "Returing file name : prepared/validation/part-00000-85addac2-a753-4bc2-b157-26ff8f5d5952-c000.csv\n",
      "s3://sagemaker-us-west-2-802439482869/debugger\n"
     ]
    }
   ],
   "source": [
    "#Since we are using powerful CPU/GPU instances for training over hours, you can choose to use a single file \n",
    "#for training and validation instead of the entrie dataset to save some time and trainging costs.  Change the variable\n",
    "#use_full_data to True to use the complete dataset\n",
    "use_full_data=False\n",
    "\n",
    "#Different train and validation inputs\n",
    "#define the data type and paths to the training and validation datasets\n",
    "if use_full_data == False:\n",
    "    train_input = TrainingInput(\"s3://{}/{}\".format(s3_bucket, get_file_in_bucket('train',1)), content_type=content_type)\n",
    "    validation_input = TrainingInput(\"s3://{}/{}\".format(s3_bucket, get_file_in_bucket('validation',1)), content_type=content_type)\n",
    "else:\n",
    "    train_input = TrainingInput(\"s3://{}/{}/{}/\".format(s3_bucket, s3_prefix, 'train'), content_type=content_type, distribution='ShardedByS3Key')\n",
    "    validation_input = TrainingInput(\"s3://{}/{}/{}/\".format(s3_bucket, s3_prefix, 'validation'), content_type=content_type, distribution='ShardedByS3Key')\n",
    "\n",
    "##Debugger output needs to be saved in the session bucket\n",
    "debugger_bucket = sagemaker.Session().default_bucket()\n",
    "debugger_path = \"s3://{}/debugger\".format(debugger_bucket)\n",
    "\n",
    "print(debugger_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Train XGBoost model with Amazon SageMaker Debugger enabled. <a id='train'></a>\n",
    "\n",
    "Now train an XGBoost model with Amazon SageMaker Debugger enabled and monitor the training jobs. This is done using the Amazon SageMaker Estimator API. While the training job is running, use Amazon SageMaker Debugger API to access saved model parameters in real time and visualize them. You can rely on Amazon SageMaker Debugger to take care of downloading a fresh set of model parameters every time you query for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker Debugger is available in Amazon SageMaker XGBoost container version 0.90-2 or later. If you want to use XGBoost with Amazon SageMaker Debugger, you have to specify `repo_version='0.90-2'` in the `get_image_uri` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Build the XGBoost container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker Debugger is available in Amazon SageMaker XGBoost container version 0.90-2 or later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_job_name = \"weather-prediction-regression\"\n",
    "\n",
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"reg:squarederror\",\n",
    "        \"num_round\":\"5\"}\n",
    "\n",
    "save_interval = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-802439482869/debugger\n"
     ]
    }
   ],
   "source": [
    "print(debugger_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_estimator = Estimator(\n",
    "    role=role,\n",
    "    base_job_name=base_job_name,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.24xlarge', \n",
    "    volume_size=1000, # 5 GB \n",
    "    image_uri=container,\n",
    "    hyperparameters=hyperparameters,\n",
    "    max_run=3600,\n",
    "    debugger_hook_config=DebuggerHookConfig(\n",
    "        s3_output_path=debugger_path,\n",
    "        collection_configs=[\n",
    "            CollectionConfig(name=\"feature_importance\", parameters={\"save_interval\": str(save_interval)}),\n",
    "            CollectionConfig(name=\"average_shap\", parameters={\"save_interval\": str(save_interval)})\n",
    "        ],\n",
    "    ),\n",
    "    rules=[\n",
    "        Rule.sagemaker(\n",
    "            rule_configs.loss_not_decreasing(),\n",
    "            rule_parameters={\n",
    "                \"collection_names\": \"metrics\",\n",
    "                \"num_steps\": str(save_interval * 2),\n",
    "            },\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the next step, start a training job by using the Estimator object you created above. This job is started in an asynchronous, non-blocking way. This means that control is passed back to the notebook and further commands can be run while the training job is progressing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-08 23:18:49 Starting - Starting the training job...\n",
      "2021-08-08 23:19:12 Starting - Launching requested ML instancesLossNotDecreasing: InProgress\n",
      "ProfilerReport-1628464729: InProgress\n",
      "...\n",
      "2021-08-08 23:19:45 Starting - Preparing the instances for training.........\n",
      "2021-08-08 23:21:17 Downloading - Downloading input data...\n",
      "2021-08-08 23:21:50 Training - Training image download completed. Training in progress.\n",
      "2021-08-08 23:21:50 Uploading - Uploading generated training model.\u001b[34m[2021-08-08 23:21:47.088 ip-10-0-153-242.us-west-2.compute.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value reg:squarederror to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34m[2021-08-08 23:21:47.979 ip-10-0-153-242.us-west-2.compute.internal:1 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-08-08 23:21:47.979 ip-10-0-153-242.us-west-2.compute.internal:1 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-08-08 23:21:47.979 ip-10-0-153-242.us-west-2.compute.internal:1 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-08-08 23:21:47.980 ip-10-0-153-242.us-west-2.compute.internal:1 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-08-08 23:21:47.980 ip-10-0-153-242.us-west-2.compute.internal:1 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mINFO:root:Debug hook created from config\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 772304 rows and 18 columns\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 220162 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.40000#011validation-rmse:0.40000\u001b[0m\n",
      "\u001b[34m[2021-08-08 23:21:48.271 ip-10-0-153-242.us-west-2.compute.internal:1 INFO hook.py:413] Monitoring the collections: feature_importance, metrics, losses, average_shap\u001b[0m\n",
      "\u001b[34m[2021-08-08 23:21:48.274 ip-10-0-153-242.us-west-2.compute.internal:1 INFO hook.py:476] Hook is writing from the hook with pid: 1\n",
      "\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.32000#011validation-rmse:0.32000\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.25599#011validation-rmse:0.25600\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.20480#011validation-rmse:0.20480\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.16383#011validation-rmse:0.16384\u001b[0m\n",
      "\n",
      "2021-08-08 23:22:17 Completed - Training job completed\n",
      "Training seconds: 55\n",
      "Billable seconds: 55\n"
     ]
    }
   ],
   "source": [
    "xgboost_estimator.fit(\n",
    "    {\"train\": train_input, \"validation\": validation_input},\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Manually analyze debugger output \n",
    "\n",
    "As a result of the above command, Amazon SageMaker starts **one training job and one rule job** for you. The first one is the job that produces the model parameters to be analyzed. The second one analyzes the model parameters to check if `train-error` and `validation-error` are not decreasing at any point during training.\n",
    "\n",
    "Check the status of the training job below.\n",
    "After your training job is started, Amazon SageMaker starts a rule-execution job to run the LossNotDecreasing rule.  \n",
    "\n",
    "The cell below will block till the training job is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job status: Completed, Rule Evaluation Status: InProgress\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for _ in range(100):\n",
    "    job_name = xgboost_estimator.latest_training_job.name\n",
    "    client = xgboost_estimator.sagemaker_session.sagemaker_client\n",
    "    description = client.describe_training_job(TrainingJobName=job_name)\n",
    "    training_job_status = description[\"TrainingJobStatus\"]\n",
    "    rule_job_summary = xgboost_estimator.latest_training_job.rule_job_summary()\n",
    "    rule_evaluation_status = rule_job_summary[0][\"RuleEvaluationStatus\"]\n",
    "    print(\n",
    "        \"Training job status: {}, Rule Evaluation Status: {}\".format(\n",
    "            training_job_status, rule_evaluation_status\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if training_job_status in [\"Completed\", \"Failed\"]:\n",
    "        break\n",
    "\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Check the status of the Rule Evaluation Job\n",
    "\n",
    "To get the rule evaluation job that Amazon SageMaker started for you, run the command below. The results show you the `RuleConfigurationName`, `RuleEvaluationJobArn`, `RuleEvaluationStatus`, `StatusDetails`, and `RuleEvaluationJobArn`.\n",
    "If the model parameters meet a rule evaluation condition, the rule execution job throws a client error with `RuleEvaluationConditionMet`.\n",
    "\n",
    "The logs of the rule evaluation job are available in the Cloudwatch Logstream `/aws/sagemaker/ProcessingJobs` with `RuleEvaluationJobArn`.\n",
    "\n",
    "You can see that once the rule execution job starts, it identifies the loss not decreasing situation in the training job, it raises the `RuleEvaluationConditionMet` exception, and it ends the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'RuleConfigurationName': 'LossNotDecreasing',\n",
       "  'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-west-2:802439482869:processing-job/weather-prediction-regress-lossnotdecreasing-00e9e924',\n",
       "  'RuleEvaluationStatus': 'InProgress',\n",
       "  'LastModifiedTime': datetime.datetime(2021, 8, 8, 23, 22, 17, 806000, tzinfo=tzlocal())},\n",
       " {'RuleConfigurationName': 'ProfilerReport-1628464729',\n",
       "  'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-west-2:802439482869:processing-job/weather-prediction-regress-profilerreport-1628464729-47485b95',\n",
       "  'RuleEvaluationStatus': 'InProgress',\n",
       "  'LastModifiedTime': datetime.datetime(2021, 8, 8, 23, 22, 13, 80000, tzinfo=tzlocal())}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_estimator.latest_training_job.rule_job_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-802439482869/debugger/weather-prediction-regression-2021-08-08-23-18-48-922/debug-output'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_estimator.latest_job_debugger_artifacts_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've trained the system, analyze the data.  Here, you focus on after-the-fact analysis.\n",
    "\n",
    "You import a basic analysis library, which defines the concept of trial, which represents a single training run.\n",
    "\n",
    "\n",
    "Before getting to analysis, here are some notes on concepts being used in Amazon SageMaker Debugger that help with analysis.\n",
    "- ***Trial*** - Object that is a centerpiece of the SageMaker Debugger API when it comes to getting access to model parameters. It is a top level abstract that represents a single run of a training job. All model parameters emitted by a training job are associated with its trial.\n",
    "- ***Tensor*** - Object that represents model parameters, such as weights, gradients, accuracy, and loss, that are saved during training job.\n",
    "\n",
    "For more details on aforementioned concepts as well as on SageMaker Debugger API in general (including examples) see [SageMaker Debugger Analysis API](https://github.com/awslabs/sagemaker-debugger/blob/master/docs/analysis.md) documentation.\n",
    "\n",
    "In the following code cell, use a ***Trial*** to access model parameters. You can do that by inspecting currently running training job and extract necessary parameters from its debug configuration to instruct SageMaker Debugger where the data you are looking for is located. Keep in mind the following:\n",
    "- model parameters are being stored in your own S3 bucket to which you can navigate and manually inspect its content if desired.\n",
    "- You might notice a slight delay before trial object is created. This is normal as SageMaker Debugger monitors the corresponding bucket and waits until model parameters to appear. The delay is introduced by less than instantaneous upload of model parameters from a training container to your S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-08-08 23:22:31.992 ip-172-16-11-227:17594 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "s3://sagemaker-us-west-2-802439482869/debugger/weather-prediction-regression-2021-08-08-23-18-48-922/debug-output\n",
      "[2021-08-08 23:22:32.033 ip-172-16-11-227:17594 INFO s3_trial.py:42] Loading trial debug-output at path s3://sagemaker-us-west-2-802439482869/debugger/weather-prediction-regression-2021-08-08-23-18-48-922/debug-output\n"
     ]
    }
   ],
   "source": [
    "from smdebug.trials import create_trial\n",
    "\n",
    "s3_output_path = xgboost_estimator.latest_job_debugger_artifacts_path()\n",
    "\n",
    "print(s3_output_path)\n",
    "trial = create_trial(s3_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can list all model parameters that you want to analyze. Each one of these names is the name of a model parameter. The name is a combination of the feature name, which in these cases, is auto-assigned by XGBoost, and whether it's an evaluation metric, feature importance, or SHAP value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-08-08 23:22:32.248 ip-172-16-11-227:17594 INFO trial.py:198] Training has ended, will refresh one final time in 1 sec.\n",
      "[2021-08-08 23:22:33.267 ip-172-16-11-227:17594 INFO trial.py:210] Loaded all steps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['average_shap/f0',\n",
       " 'average_shap/f1',\n",
       " 'average_shap/f10',\n",
       " 'average_shap/f11',\n",
       " 'average_shap/f12',\n",
       " 'average_shap/f13',\n",
       " 'average_shap/f14',\n",
       " 'average_shap/f15',\n",
       " 'average_shap/f16',\n",
       " 'average_shap/f17',\n",
       " 'average_shap/f2',\n",
       " 'average_shap/f3',\n",
       " 'average_shap/f4',\n",
       " 'average_shap/f5',\n",
       " 'average_shap/f6',\n",
       " 'average_shap/f7',\n",
       " 'average_shap/f8',\n",
       " 'average_shap/f9',\n",
       " 'train-rmse',\n",
       " 'validation-rmse']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.tensor_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each model parameter, we can get the values at all saved steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0.], dtype=float32)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Check the values of individual tensors\n",
    "trial.tensor(\"average_shap/f10\").values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0.399997])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Check the values of train rmse\n",
    "trial.tensor(\"train-rmse\").values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0.400004])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Check the values of validation rmse\n",
    "trial.tensor(\"validation-rmse\").values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we performed manual analysis of tensors and metrics capatured by SageMaker Debugger during the training process.  Note that you can plot these values for better visualization or use the SageMaker Studio environment to see built-in visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
