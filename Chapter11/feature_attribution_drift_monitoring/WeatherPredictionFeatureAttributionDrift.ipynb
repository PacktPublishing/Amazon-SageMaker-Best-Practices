{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Feature attribute drift monitoring with Amazon SageMaker Clarify\n",
    "\n",
    "This notebook provides a walkthrough of the high level steps involved in monitoring a production ML model with SageMaker Clarify for feature attribute drift. To demonstrate the data drift monitoring we will use a pre-trained model to deploy an endpoint.  We provide the pre-trained model artifact along with baseline and test datasets along with this notebook.\n",
    "\n",
    "1. Set up\n",
    "2. Enable datacapture on a SageMaker endpoint \n",
    "3. Generate a baseline with ModelExplainabilityMonitor \n",
    "4. Schedule continous monitoring to monitor predictions for feature attribute drift on a regular basis.\n",
    "5. Analyze feature attribute drift monitoring results\n",
    "6. Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "from botocore.response import StreamingBody\n",
    "from sagemaker import get_execution_role, session\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sagemaker import get_execution_role, image_uris, Session\n",
    "\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "from sagemaker.clarify import (\n",
    "    BiasConfig,\n",
    "    DataConfig,\n",
    "    ModelConfig,\n",
    "    ModelPredictedLabelConfig,\n",
    "    SHAPConfig,\n",
    ")\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_monitor import (\n",
    "    CronExpressionGenerator,\n",
    "    DataCaptureConfig,\n",
    "    EndpointInput,\n",
    "    ExplainabilityAnalysisConfig,\n",
    "    ModelExplainabilityMonitor,\n",
    ")\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoleArn: arn:aws:iam::802439482869:role/service-role/AmazonSageMaker-ExecutionRole-20210418T143524\n",
      "Capture path: s3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/datacapture\n",
      "Report path: s3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/reports\n"
     ]
    }
   ],
   "source": [
    "region = boto3.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "print(\"RoleArn: {}\".format(role))\n",
    "\n",
    "#This is the bucket into which the data is captured\n",
    "bucket = 'datascience-environment-notebookinstance--06dc7a0224df'\n",
    "prefix = \"FeatureAttributionMonitoring\"\n",
    "\n",
    "data_capture_prefix = \"{}/datacapture\".format(prefix)\n",
    "s3_capture_upload_path = \"s3://{}/{}\".format(bucket, data_capture_prefix)\n",
    "reports_prefix = \"{}/reports\".format(prefix)\n",
    "s3_report_path = \"s3://{}/{}\".format(bucket, reports_prefix)\n",
    "\n",
    "ground_truth_upload_path = (\n",
    "    f\"s3://{bucket}/{prefix}/ground_truth_data/{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    ")\n",
    "\n",
    "print(\"Capture path: {}\".format(s3_capture_upload_path))\n",
    "print(\"Report path: {}\".format(s3_report_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Setup service clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.Session().client(\"s3\")\n",
    "sagemaker_client = boto3.Session().client(\"sagemaker\")\n",
    "sagemaker_runtime_client = boto3.Session().client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Enable datacapture on a SageMaker endpoint \n",
    "\n",
    "Create an endpoint to showcase the data capture capability in action.\n",
    "\n",
    "For the endpoint we will use a pre-trained XGBoost model that is ready to deploy. This model was trained in the previous chapters using the weather dataset and has been included in the model directory for ease of use.\n",
    "\n",
    "Note that you can also train a new model and use your model and data below as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Upload the model object into S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = open(\"model/weather-prediction-model.tar.gz\", \"rb\")\n",
    "s3_key = os.path.join(prefix, \"weather-prediction-model.tar.gz\")\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(s3_key).upload_fileobj(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2  Create SageMaker Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:  weather-pred-model-monitor-2021-08-05-0123\n",
      "https://datascience-environment-notebookinstance--06dc7a0224df.s3-us-west-2.amazonaws.com/FeatureAttributionMonitoring/weather-prediction-model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"weather-pred-model-monitor-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "print(\"Model name: \", model_name)\n",
    "\n",
    "model_url = \"https://{}.s3-{}.amazonaws.com/{}/weather-prediction-model.tar.gz\".format(\n",
    "    bucket, region, prefix\n",
    ")\n",
    "\n",
    "print(model_url)\n",
    "\n",
    "image_uri = retrieve(\"xgboost\", boto3.Session().region_name, \"1.2-1\")\n",
    "\n",
    "model = Model(name=model_name, image_uri=image_uri, model_data=model_url, role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value\n"
     ]
    }
   ],
   "source": [
    "##Test and validation files to use with model\n",
    "test_dataset=\"data/t_file.csv\"\n",
    "validation_dataset = \"data/data-drift-baseline-data.csv\"\n",
    "dataset_type = \"text/csv\"\n",
    "\n",
    "with open(validation_dataset) as f:\n",
    "    headers_line = f.readline().rstrip()\n",
    "    all_headers = headers_line.split(\",\")\n",
    "##Get the label name\n",
    "label_header = all_headers[0]\n",
    "print(label_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3  Configure datacapture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable data capture on the endpoint, you specify the new capture option called `DataCaptureConfig`. On enabling data capture, input to and output from the SageMaker endpoint are captured and saved in S3. Input captured includes the live inference traffic requests and output captured includes predictions from the deployed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EndpointName=weather-prediction-fa-drift-model-monitor-2021-08-05-01-23-52\n",
      "---------------!"
     ]
    }
   ],
   "source": [
    "endpoint_name = \"weather-prediction-fa-drift-model-monitor-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"EndpointName={}\".format(endpoint_name))\n",
    "\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True, sampling_percentage=100, destination_s3_uri=s3_capture_upload_path\n",
    ")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    data_capture_config=data_capture_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Capture data from endpoint "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step invokes the endpoint with included sample data for about 3 minutes. Data is captured based on the sampling percentage specified and the capture continues until the data capture option is turned off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Use the test file in the data directory  to execute inferences using the test file 't_file.csv' provided\n",
    "with open('data/t_file.csv', 'r') as TF:\n",
    "    t_lines = TF.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define a method to run inferences against the endpoint\n",
    "def get_predictions():\n",
    "    smrt = boto3.Session().client(\"sagemaker-runtime\")\n",
    "    #Skip the first line since it has column headers\n",
    "    for tl in t_lines[1:50]:\n",
    "        #Remove the first column since it is the label\n",
    "        test_list = tl.split(\",\")\n",
    "        test_list.pop(0)\n",
    "        test_string = ','.join([str(elem) for elem in test_list])\n",
    "        \n",
    "        #print(\"invoking with payload \" + test_string)\n",
    "    \n",
    "        result = smrt.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                   ContentType=\"text/csv\",\n",
    "                                   Body=test_string)\n",
    "        rbody = StreamingBody(raw_stream=result['Body'],content_length=int(result['ResponseMetadata']['HTTPHeaders']['content-length']))\n",
    "        #print(f\"Result from {result['InvokedProductionVariant']} = {rbody.read().decode('utf-8')}\")\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................."
     ]
    }
   ],
   "source": [
    "#Get predictions\n",
    "get_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5  View captured data\n",
    "\n",
    "Now list the data capture files stored in Amazon S3. You should expect to see different files from different time periods organized based on the hour in which the invocation occurred. The format of the Amazon S3 path is:\n",
    "\n",
    "`s3://{destination-bucket-prefix}/{endpoint-name}/{variant-name}/yyyy/mm/dd/hh/filename.jsonl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/datacapture'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_capture_upload_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Capture Files:\n",
      "FeatureAttributionMonitoring/datacapture/weather-prediction-fa-drift-model-monitor-2021-08-05-01-23-52/AllTraffic/2021/08/05/01/31-24-677-5be726a8-259e-4b01-9020-be447b2f1706.jsonl\n"
     ]
    }
   ],
   "source": [
    "#Note : If you see an error in this cell, it could be because the captured files didn't appear in S3 yet.\n",
    "#Retry after a minute.\n",
    "current_endpoint_capture_prefix = \"{}/{}\".format(data_capture_prefix, endpoint_name)\n",
    "\n",
    "result = s3_client.list_objects(Bucket=bucket, Prefix=current_endpoint_capture_prefix)\n",
    "capture_files = [capture_file.get(\"Key\") for capture_file in result.get(\"Contents\")]\n",
    "print(\"Found Capture Files:\")\n",
    "print(\"\\n \".join(capture_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, view the content of a single capture file. Take a quick peek at the first few lines in the captured file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text/csv\",\"mode\":\"INPUT\",\"data\":\"0,2020,12,4,31,0,19.0,0.0,6.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\\n\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"text/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"-4.902510643005371\",\"encoding\":\"CSV\"}},\"eventMetadata\":{\"eventId\":\"0b594743-f75f-4110-ace7-d8669acb5728\",\"inferenceTime\":\"2021-08-05T01:31:24Z\"},\"eventVersion\":\"0\"}\n",
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text/csv\",\"mode\":\"INPUT\",\"data\":\"0,2020,12,4,31,0,19.0,0.0,6.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\\n\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"text/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"-4.902510643005371\",\"encoding\":\"CSV\"}},\"eventMetadata\":{\"eventId\":\"1d469416-f217-4b7f-9707-35f5b0d3815c\",\"inferenceTime\":\"2021-08-05T01:31:25Z\"},\"eventVersion\":\"0\"}\n",
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text/csv\",\"mode\":\"INPUT\",\"data\":\"0,2020,12,4,31,0,19.0,0.0,6.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\\n\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"text/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"-4.902510643005371\",\"encoding\":\"CSV\"}},\"eventMetadata\":{\"eventId\":\"6e960957-8598-4fb8-a2a3-c07ead392149\",\"inferenceTime\":\"2021-08-05T01:31:25Z\"},\"eventVersion\":\"0\"}\n",
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text/csv\",\"mode\":\"INPUT\",\"data\":\"0,2020,12,4,31,0,19.0,0.0,6.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\\n\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"text/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"-4.902510643005371\",\"encoding\":\"CSV\"}},\"eventMetadata\":{\"eventId\":\"9ac24ef5-536d-4e8f-89c9-7234e9418d97\",\"inferenceTime\":\"2021-08-05T01:31:26Z\"},\"eventVersion\":\"0\"}\n",
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"text/csv\",\"mode\":\"INPUT\",\"data\":\"0,2020,12,4,31,0,19.0,0.0,6.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\\n\",\"encoding\":\"CSV\"},\"endpointOutput\":{\"observedContentType\":\"text/csv; charset=utf-8\",\"mode\":\"OUTPUT\",\"data\":\"-4.902510643005371\",\"encoding\":\"CSV\"}},\"eventMetad\n"
     ]
    }
   ],
   "source": [
    "def get_obj_body(obj_key):\n",
    "    return s3_client.get_object(Bucket=bucket, Key=obj_key).get(\"Body\").read().decode(\"utf-8\")\n",
    "\n",
    "\n",
    "capture_file = get_obj_body(capture_files[-1])\n",
    "print(capture_file[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the contents of a single line is present below in a formatted JSON file to observe a little better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"captureData\": {\n",
      "    \"endpointInput\": {\n",
      "      \"observedContentType\": \"text/csv\",\n",
      "      \"mode\": \"INPUT\",\n",
      "      \"data\": \"0,2020,12,4,31,0,19.0,0.0,6.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0\\n\",\n",
      "      \"encoding\": \"CSV\"\n",
      "    },\n",
      "    \"endpointOutput\": {\n",
      "      \"observedContentType\": \"text/csv; charset=utf-8\",\n",
      "      \"mode\": \"OUTPUT\",\n",
      "      \"data\": \"-4.902510643005371\",\n",
      "      \"encoding\": \"CSV\"\n",
      "    }\n",
      "  },\n",
      "  \"eventMetadata\": {\n",
      "    \"eventId\": \"0b594743-f75f-4110-ace7-d8669acb5728\",\n",
      "    \"inferenceTime\": \"2021-08-05T01:31:24Z\"\n",
      "  },\n",
      "  \"eventVersion\": \"0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(json.loads(capture_file.split(\"\\n\")[0]), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a baseline with ModelExplainability Monitor\n",
    "\n",
    "A baselining job runs predictions on validation dataset and suggests constraints. `suggest_baseline()` method starts a `SageMakerClarifyProcessor` processing job using SageMaker Clarify container to generate the constraints.\n",
    "\n",
    "A feature attribution drift baseline job needs multiple inputs – the data to use for baselining, a model to give predictions and SHAP configuration. Let’s look at the various configuration objects that capture these details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline data uri: s3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/baselining/data\n",
      "Baseline results uri: s3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/baselining/results\n"
     ]
    }
   ],
   "source": [
    "baseline_prefix = prefix + \"/baselining\"\n",
    "baseline_data_prefix = baseline_prefix + \"/data\"\n",
    "baseline_results_prefix = baseline_prefix + \"/results\"\n",
    "\n",
    "baseline_data_uri = f\"s3://{bucket}/{baseline_data_prefix}\"\n",
    "baseline_results_uri = f\"s3://{bucket}/{baseline_results_prefix}\"\n",
    "model_bias_baselining_job_result_uri = f\"{baseline_results_uri}/model_bias\"\n",
    "model_explainability_baselining_job_result_uri = f\"{baseline_results_uri}/model_explainability\"\n",
    "\n",
    "\n",
    "print(f\"Baseline data uri: {baseline_data_uri}\")\n",
    "print(f\"Baseline results uri: {baseline_results_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Create ModelExplainabilityMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "model_explainability_monitor = ModelExplainabilityMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=session,\n",
    "    max_runtime_in_seconds=3000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Configure DataConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the explainability baselining job shares the validation dataset with the bias baselining job, so here it uses the same `DataConfig`, the only difference is the job output URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainability_data_config = DataConfig(\n",
    "    s3_data_input_path=validation_dataset,\n",
    "    s3_output_path=model_explainability_baselining_job_result_uri,\n",
    "    label=label_header,\n",
    "    headers=all_headers,\n",
    "    dataset_type=dataset_type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Configure SHAPConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the Clarify explainer offers a scalable and efficient implementation of SHAP, so the explainability config is `SHAPConfig`, including\n",
    "* baseline: A list of rows (at least one) or S3 object URI to be used as the baseline dataset in the Kernel SHAP algorithm. The format should be the same as the dataset format. Each row should contain only the feature columns/values and omit the label column/values.\n",
    "* num_samples: Number of samples to be used in the Kernel SHAP algorithm. This number determines the size of the generated synthetic dataset to compute the SHAP values.\n",
    "* agg_method: Aggregation method for global SHAP values. Valid values are\n",
    "  * \"mean_abs\" (mean of absolute SHAP values for all instances),\n",
    "  * \"median\" (median of SHAP values for all instances) and\n",
    "  * \"mean_sq\" (mean of squared SHAP values for all instances).\n",
    "* use_logit: Indicator of whether the logit function is to be applied to the model predictions. Default is False. If \"use_logit\" is true then the SHAP values will have log-odds units.\n",
    "* save_local_shap_values (bool): Indicator of whether to save the local SHAP values in the output location. Default is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ismobile  year  month  quarter  day  isBadAir  location   city  \\\n",
      "0             0  2020     12        4   31         0      19.0    0.0   \n",
      "1             0  2020     12        4   31         0      19.0    0.0   \n",
      "2             0  2020     12        4   31         0      19.0    0.0   \n",
      "3             0  2020     12        4   31         0      19.0    0.0   \n",
      "4             0  2020     12        4   31         0      19.0    0.0   \n",
      "...         ...   ...    ...      ...  ...       ...       ...    ...   \n",
      "23154         0  2021      1        1    1         0    3424.0  127.0   \n",
      "23155         0  2020     12        4   31         0     333.0  165.0   \n",
      "23156         0  2020     12        4   31         0     333.0  165.0   \n",
      "23157         0  2020     12        4   31         0     333.0  165.0   \n",
      "23158         0  2020     12        4   31         0     333.0  165.0   \n",
      "\n",
      "       sourcename  sourcetype  no2   o3  pm10  pm25  so2   co  \n",
      "0             6.0         0.0  0.0  0.0   0.0   0.0  0.0  1.0  \n",
      "1             6.0         0.0  0.0  0.0   0.0   0.0  0.0  1.0  \n",
      "2             6.0         0.0  0.0  0.0   0.0   0.0  0.0  1.0  \n",
      "3             6.0         0.0  0.0  0.0   0.0   0.0  0.0  1.0  \n",
      "4             6.0         0.0  0.0  0.0   0.0   0.0  0.0  1.0  \n",
      "...           ...         ...  ...  ...   ...   ...  ...  ...  \n",
      "23154        13.0         0.0  0.0  0.0   0.0   0.0  0.0  1.0  \n",
      "23155         5.0         0.0  0.0  0.0   0.0   0.0  0.0  1.0  \n",
      "23156         5.0         0.0  0.0  0.0   0.0   0.0  0.0  1.0  \n",
      "23157         5.0         0.0  0.0  0.0   0.0   0.0  0.0  1.0  \n",
      "23158         5.0         0.0  0.0  0.0   0.0   0.0  0.0  1.0  \n",
      "\n",
      "[23159 rows x 16 columns]\n",
      "[[0.0, 2020.2729824258388, 8.876721792823524, 3.1487542640010364, 22.46064165119392, 0.08730946932078242, 1685.4437151863206, 366.1484951854571, 7.059328986571096, 0.0, 0.23731594628438188, 0.20812643032946154, 0.1703441426659182, 0.14236365991623126, 0.13722526879398939, 0.10432229370870935]]\n"
     ]
    }
   ],
   "source": [
    "# Here use the mean value of test dataset as SHAP baseline\n",
    "test_dataframe_full = pd.read_csv(test_dataset, header=[0])\n",
    "#Remove the first column since it is the label\n",
    "test_dataframe = test_dataframe_full.iloc[:, 1:]\n",
    "print(test_dataframe)\n",
    "\n",
    "shap_baseline = [list(test_dataframe.mean())]\n",
    "\n",
    "print(shap_baseline)\n",
    "\n",
    "shap_config = SHAPConfig(\n",
    "    baseline=shap_baseline,\n",
    "    num_samples=50,\n",
    "    #num_samples=100,\n",
    "    agg_method=\"mean_abs\",\n",
    "    save_local_shap_values=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Configure ModelConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For explainability monitoring, the processing job stands up a shadow endpoint to compute the bias metrics.  `ModelConfig` captures configuration of this model/endpoint.  Once the bias metrics are calculated, the processing will delete the shadow endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_instance_count=1\n",
    "\n",
    "endpoint_instance_type=\"ml.m4.xlarge\"\n",
    "    \n",
    "model_config = ModelConfig(\n",
    "    model_name=model_name,\n",
    "    instance_count=endpoint_instance_count,\n",
    "    instance_type=endpoint_instance_type,\n",
    "    content_type=dataset_type,\n",
    "    accept_type=dataset_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Kick off baselining job\n",
    "\n",
    "The same model_config is required, because the explainability baselining job needs to create shadow endpoint to get predictions for generated synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  baseline-suggestion-job-2021-08-05-01-33-36-705\n",
      "Inputs:  [{'InputName': 'dataset', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-west-2-802439482869/baseline-suggestion-job-2021-08-05-01-33-36-705/input/dataset/data-drift-baseline-data.csv', 'LocalPath': '/opt/ml/processing/input/data', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'analysis_config', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/baselining/results/model_explainability/analysis_config.json', 'LocalPath': '/opt/ml/processing/input/config', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'analysis_result', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/baselining/results/model_explainability', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "ModelExplainabilityMonitor baselining job: baseline-suggestion-job-2021-08-05-01-33-36-705\n"
     ]
    }
   ],
   "source": [
    "model_explainability_monitor.suggest_baseline(\n",
    "    data_config=model_explainability_data_config,\n",
    "    model_config=model_config,\n",
    "    explainability_config=shap_config,\n",
    ")\n",
    "print(\n",
    "    f\"ModelExplainabilityMonitor baselining job: {model_explainability_monitor.latest_baselining_job_name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for baselining job to finish (or skip this cell because the monitor to be scheduled will wait for it anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!"
     ]
    }
   ],
   "source": [
    "##This cell may take upto an hour to complete\n",
    "model_explainability_monitor.latest_baselining_job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can inspects the constraints suggested by the baseline job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelExplainabilityMonitor suggested constraints: s3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/baselining/results/model_explainability/analysis.json\n",
      "{\n",
      "    \"version\": \"1.0\",\n",
      "    \"explanations\": {\n",
      "        \"kernel_shap\": {\n",
      "            \"label0\": {\n",
      "                \"global_shap_values\": {\n",
      "                    \"ismobile\": 0.007195967708976887,\n",
      "                    \"year\": 0.00915509152079749,\n",
      "                    \"month\": 0.010604975057950656,\n",
      "                    \"quarter\": 0.007343707080704893,\n",
      "                    \"day\": 0.007659021851217411,\n",
      "                    \"isBadAir\": 0.011286032667595558,\n",
      "                    \"location\": 0.019209560107642507,\n",
      "                    \"city\": 0.019061098353111414,\n",
      "                    \"sourcename\": 0.019486345509024436,\n",
      "                    \"sourcetype\": 0.007337886307036748,\n",
      "                    \"no2\": 0.007498285464821051,\n",
      "                    \"o3\": 0.0074407831832228695,\n",
      "                    \"pm10\": 0.014471052283190119,\n",
      "                    \"pm25\": 0.007536781743215739,\n",
      "                    \"so2\": 0.007245818870827539,\n",
      "                    \"co\": 0.03653382020925509\n",
      "                },\n",
      "                \"expected_value\": 0.17167794704437256\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_explainability_constraints = model_explainability_monitor.suggested_constraints()\n",
    "print()\n",
    "print(\n",
    "    f\"ModelExplainabilityMonitor suggested constraints: {model_explainability_constraints.file_s3_uri}\"\n",
    ")\n",
    "print(S3Downloader.read_file(model_explainability_constraints.file_s3_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Schedule continous monitoring\n",
    "When that we have the baseline constraints let's analyze and monitor the endpoint on a continuous basis with a Monitoring Schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Generate prediction data and ground truth for feature attributiobn drift  Monitoring\n",
    "\n",
    "Start generating some artificial traffic.  The cell below starts a thread to send some traffic to the endpoint. Note that you need to stop the kernel to terminate this thread. If there is no traffic, the monitoring jobs are marked as `Failed` since there is no data to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from time import sleep\n",
    "import time\n",
    "\n",
    "#Invoke the endpoint in a loop\n",
    "def invoke_endpoint_forever():\n",
    "    while True:\n",
    "        get_predictions()\n",
    "        \n",
    "# Note that you need to stop the kernel to stop the invocations\n",
    "thread = Thread(target=invoke_endpoint_forever)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...."
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "test_dataset_size  = 350\n",
    "\n",
    "def ground_truth_with_id(inference_id):\n",
    "    random.seed(inference_id)  # to get consistent results\n",
    "    rand = random.random()\n",
    "    # format required by the merge container\n",
    "    return {\n",
    "        \"groundTruthData\": {\n",
    "            #\"data\": \"1\" if rand < 0.7 else \"0\",  # randomly generate positive labels 70% of the time # randomly generate positive labels 70% of the time #\n",
    "             # TODO : Need to make this a decimal??\n",
    "            \"data\": rand,\n",
    "            \"encoding\": \"CSV\",\n",
    "        },\n",
    "        \"eventMetadata\": {\n",
    "            \"eventId\": str(inference_id),\n",
    "        },\n",
    "        \"eventVersion\": \"0\",\n",
    "    }\n",
    "\n",
    "\n",
    "def upload_ground_truth(upload_time):\n",
    "    records = [ground_truth_with_id(i) for i in range(test_dataset_size)]\n",
    "    fake_records = [json.dumps(r) for r in records]\n",
    "    data_to_upload = \"\\n\".join(fake_records)\n",
    "    target_s3_uri = f\"{ground_truth_upload_path}/{upload_time:%Y/%m/%d/%H/%M%S}.jsonl\"\n",
    "    print(f\"Uploading {len(fake_records)} records to\", target_s3_uri)\n",
    "    S3Uploader.upload_string_as_file_body(data_to_upload, target_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 350 records to s3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/ground_truth_data/2021-08-05-01-23-51/2021/08/05/02/2251.jsonl\n",
      "...."
     ]
    }
   ],
   "source": [
    "NUM_GROUND_TRUTH_RECORDS = 300\n",
    "\n",
    "def generate_fake_ground_truth_forever():\n",
    "    j = 0\n",
    "    while True:\n",
    "        fake_records = [ground_truth_with_id(i) for i in range(NUM_GROUND_TRUTH_RECORDS)]\n",
    "        #upload_ground_truth(fake_records, datetime.utcnow())\n",
    "        upload_ground_truth(datetime.utcnow())\n",
    "        j = (j + 1) % 5\n",
    "        sleep(60 * 60)  # do this once an hour\n",
    "\n",
    "\n",
    "gt_thread = Thread(target=generate_fake_ground_truth_forever)\n",
    "gt_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 350 records to s3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/ground_truth_data/2021-08-05-01-23-51/2021/08/05/01/2253.jsonl\n",
      "...."
     ]
    }
   ],
   "source": [
    "# Generate data for the last hour\n",
    "upload_ground_truth(datetime.utcnow() - timedelta(hours=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 350 records to s3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/ground_truth_data/2021-08-05-01-23-51/2021/08/05/02/2255.jsonl\n",
      "....."
     ]
    }
   ],
   "source": [
    "# Generate data once a hour\n",
    "#def generate_fake_ground_truth(terminate_event):\n",
    "def generate_fake_ground_truth_forever():\n",
    "    upload_ground_truth(datetime.utcnow())\n",
    "    for _ in range(0, 60):\n",
    "        time.sleep(60)\n",
    "        #if terminate_event.is_set():\n",
    "         #   break\n",
    "\n",
    "gt_thread = Thread(target=generate_fake_ground_truth_forever)\n",
    "gt_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Create a monitoring schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call `create_monitoring_schedule()` method to schedule a hourly monitor, to analyze the data with monitoring schedule. If a baselining job has been submitted, then the monitor will automatically pick up analysis configuration from the baselining job. But if the baselining step is skipped, or the capture dataset has different nature than the training dataset, then analysis configuration has to be provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....."
     ]
    }
   ],
   "source": [
    "\n",
    "model_explainability_monitor.create_monitoring_schedule(\n",
    "    output_s3_uri=s3_report_path,\n",
    "    endpoint_input=endpoint_name,\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly()\n",
    "    #schedule_cron_expression=schedule_expression,\n",
    "    #schedule_cron_expression=CronExpressionGenerator.daily_every_x_hours(hour_interval=2, starting_hour=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Wait for the first execution\n",
    "\n",
    "Once created the schedule is started by default, here wait for the its first execution to start, then stop the schedule to avoid incurring charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....."
     ]
    }
   ],
   "source": [
    "def wait_for_execution_to_start(model_monitor):\n",
    "    print(\n",
    "        \"A hourly schedule was created above and it will kick off executions ON the hour (plus 0 - 20 min buffer).\"\n",
    "    )\n",
    "\n",
    "    print(\"Waiting for the first execution to happen\", end=\"\")\n",
    "    schedule_desc = model_monitor.describe_schedule()\n",
    "    while \"LastMonitoringExecutionSummary\" not in schedule_desc:\n",
    "        schedule_desc = model_monitor.describe_schedule()\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(60)\n",
    "    print()\n",
    "    print(\"Done! Execution has been created\")\n",
    "\n",
    "    print(\"Now waiting for execution to start\", end=\"\")\n",
    "    while schedule_desc[\"LastMonitoringExecutionSummary\"][\"MonitoringExecutionStatus\"] in \"Pending\":\n",
    "        schedule_desc = model_monitor.describe_schedule()\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(10)\n",
    "\n",
    "    print()\n",
    "    print(\"Done! Execution has started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A hourly schedule was created above and it will kick off executions ON the hour (plus 0 - 20 min buffer).\n",
      "Waiting for the first execution to happen..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Done! Execution has been created\n",
      "Now waiting for execution to start....................\n",
      "Done! Execution has started\n",
      ".........................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "wait_for_execution_to_start(model_explainability_monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait further for the execution to finish, then inspect its analysis results,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Wait for the execution to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    }
   ],
   "source": [
    "# Waits for the schedule to have last execution in a terminal status.\n",
    "def wait_for_execution_to_finish(model_monitor):\n",
    "    schedule_desc = model_monitor.describe_schedule()\n",
    "    execution_summary = schedule_desc.get(\"LastMonitoringExecutionSummary\")\n",
    "    if execution_summary is not None:\n",
    "        print(\"Waiting for execution to finish\", end=\"\")\n",
    "        while execution_summary[\"MonitoringExecutionStatus\"] not in [\n",
    "            \"Completed\",\n",
    "            \"CompletedWithViolations\",\n",
    "            \"Failed\",\n",
    "            \"Stopped\",\n",
    "        ]:\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            time.sleep(60)\n",
    "            schedule_desc = model_monitor.describe_schedule()\n",
    "            execution_summary = schedule_desc[\"LastMonitoringExecutionSummary\"]\n",
    "        print()\n",
    "        print(\"Done! Execution has finished\")\n",
    "    else:\n",
    "        print(\"Last execution not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for execution to finish.....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Done! Execution has finished\n",
      "..........................................................Uploading 350 records to s3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/ground_truth_data/2021-08-05-01-23-51/2021/08/05/03/2251.jsonl\n",
      "..........."
     ]
    }
   ],
   "source": [
    "wait_for_execution_to_finish(model_explainability_monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Analyze feature attribute drift monitoring results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".Report URI: s3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/reports/weather-prediction-fa-drift-model-monitor-2021-08-05-01-23-52/monitoring-schedule-2021-08-05-02-22-58-318/2021/08/05/03\n",
      "Found Report Files:\n",
      "s3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/reports/weather-prediction-fa-drift-model-monitor-2021-08-05-01-23-52/monitoring-schedule-2021-08-05-02-22-58-318/2021/08/05/03/analysis.json\n",
      " s3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/reports/weather-prediction-fa-drift-model-monitor-2021-08-05-01-23-52/monitoring-schedule-2021-08-05-02-22-58-318/2021/08/05/03/constraint_violations.json\n",
      " s3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/reports/weather-prediction-fa-drift-model-monitor-2021-08-05-01-23-52/monitoring-schedule-2021-08-05-02-22-58-318/2021/08/05/03/report.html\n",
      " s3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/reports/weather-prediction-fa-drift-model-monitor-2021-08-05-01-23-52/monitoring-schedule-2021-08-05-02-22-58-318/2021/08/05/03/report.ipynb\n",
      " s3://datascience-environment-notebookinstance--06dc7a0224df/FeatureAttributionMonitoring/reports/weather-prediction-fa-drift-model-monitor-2021-08-05-01-23-52/monitoring-schedule-2021-08-05-02-22-58-318/2021/08/05/03/report.pdf\n",
      "........."
     ]
    }
   ],
   "source": [
    "schedule_desc = model_explainability_monitor.describe_schedule()\n",
    "execution_summary = schedule_desc.get(\"LastMonitoringExecutionSummary\")\n",
    "if execution_summary and execution_summary[\"MonitoringExecutionStatus\"] in [\n",
    "    \"Completed\",\n",
    "    \"CompletedWithViolations\",\n",
    "]:\n",
    "    last_model_explainability_monitor_execution = model_explainability_monitor.list_executions()[-1]\n",
    "    last_model_explainability_monitor_execution_report_uri = (\n",
    "        last_model_explainability_monitor_execution.output.destination\n",
    "    )\n",
    "    print(f\"Report URI: {last_model_explainability_monitor_execution_report_uri}\")\n",
    "    last_model_explainability_monitor_execution_report_files = sorted(\n",
    "        S3Downloader.list(last_model_explainability_monitor_execution_report_uri)\n",
    "    )\n",
    "    print(\"Found Report Files:\")\n",
    "    print(\"\\n \".join(last_model_explainability_monitor_execution_report_files))\n",
    "else:\n",
    "    last_model_explainability_monitor_execution = None\n",
    "    print(\n",
    "        \"====STOP==== \\n No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are any violations compared to the baseline, they will be listed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'version': '1.0', 'violations': [{'label': 'label0', 'metric_name': 'shap', 'constraint_check_type': 'feature_attribution_drift_check', 'description': 'Feature attribution drift 0.860173572903856 exceeds threshold 0.9'}]}\n",
      "..........."
     ]
    }
   ],
   "source": [
    "if last_model_explainability_monitor_execution:\n",
    "    model_explainability_violations = (\n",
    "        last_model_explainability_monitor_execution.constraint_violations()\n",
    "    )\n",
    "    if model_explainability_violations:\n",
    "        print(model_explainability_violations.body_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  Cleanup\n",
    "\n",
    "The endpoint can keep running and capturing data, but if there is no plan to collect more data or use this endpoint further, it should be deleted to avoid incurring additional charges. Note that deleting endpoint does not delete the data that was captured during the model invocations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stop the monitors scheduled for the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deleting Monitoring Schedule with name: monitoring-schedule-2021-08-05-02-22-58-318\n",
      ".........."
     ]
    }
   ],
   "source": [
    "model_explainability_monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-36-6ced153c071e>\", line 8, in invoke_endpoint_forever\n",
      "    get_predictions()\n",
      "  File \"<ipython-input-9-79bc0b67d8af>\", line 15, in get_predictions\n",
      "    Body=test_string)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\", line 386, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\", line 705, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ValidationError: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint weather-prediction-fa-drift-model-monitor-2021-08-05-01-23-52 of account 802439482869 not found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = sagemaker_client.delete_endpoint(\n",
    "    EndpointName=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the Threads you started to create inference data and ground truth could be still running.  Go ahead and shutdown the kernel to stop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
